# ğŸª™ Gold ETL Pipeline with Apache Airflow & Docker

This project is an **automated ETL pipeline** built using **Apache Airflow**, running inside **Docker Compose**.  
It automatically **extracts**, **transforms**, and **loads** daily gold price data from [GoldAPI.io](https://www.goldapi.io/) â€” perfect for practicing Data Engineering and pipeline orchestration.

---

## âš™ï¸ Features

- ğŸ•’ **Automated scheduling** with Apache Airflow  
- ğŸŒ **Extract** gold price data from GoldAPI  
- ğŸ§® **Transform** raw JSON into structured DataFrame using pandas  
- ğŸ’¾ **Load** data into PostgreSQL or export as CSV/email  
- ğŸ³ Fully **containerized** with Docker Compose  
- ğŸ“§ Optional email notifications with attached report  

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ config/
â”‚ â””â”€â”€ airflow.cfg # Airflow configuration file
â”‚
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ gold_data_dag.py # Main Airflow DAG (Extract â†’ Transform â†’ Load)
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py # Load environment variables
â”‚ â”œâ”€â”€ extract.py # Fetch data from GoldAPI
â”‚ â”œâ”€â”€ transform.py # Clean & format the raw data
â”‚ â”œâ”€â”€ load.py # Send processed data to DB / email
â”‚ â””â”€â”€ main.py # For manual ETL testing
â”‚
â”œâ”€â”€ docker-compose.yaml # Docker setup for Airflow services
â”œâ”€â”€ .env.example # Example environment variables file
â””â”€â”€ README.md # Project documentation

---

## ğŸ§¾ Example `.env` file

Copy `.env.example` â†’ `.env` and fill your credentials:

```env
GOLD_API_URL=https://www.goldapi.io/api/XAU/USD
GOLD_API_KEY=get_your_api_key_on_website_https://www.goldapi.io/dashboard

AIRFLOW_UID=50000

GMAIL_USER=example@gmail.com
GMAIL_PASSWORD=your_app_password_here


