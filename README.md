# ğŸª™ Automated Gold Data Pipeline (Airflow + Docker)

An automated **ETL pipeline** built using **Apache Airflow** and **Docker Compose**, designed to fetch, transform, and deliver **daily gold price data** directly to your email inbox ğŸ“§.

This project is ideal for practicing **Data Engineering**, **ETL orchestration**, and **workflow automation** using real-world tools.

---

## âœ¨ Key Features

* ğŸ•’ **Automated Scheduling** â€” The pipeline runs daily through Apache Airflow.
* ğŸŒ **API Integration** â€” Fetches live gold price data from [GoldAPI.io](https://www.goldapi.io/).
* ğŸ§® **Data Transformation** â€” Cleans and formats JSON data into a structured CSV using `pandas`.
* ğŸ“§ **Email Automation** â€” Sends the processed CSV to your Gmail inbox via SMTP.
* ğŸ³ **Containerized Setup** â€” Runs entirely in Docker Compose for easy deployment and portability.

---

## ğŸ—‚ Project Structure

The project is organized for clarity and modularity:

```bash
automated_gold_pipeline/
â”œâ”€â”€ config/               # Airflow configuration
â”œâ”€â”€ dags/                 # gold DAG
â”œâ”€â”€ src/                  # ETL scripts (extract, transform, load)
â”œâ”€â”€ docker-compose.yaml   # Docker setup for Airflow services
â”œâ”€â”€ .env                  # Just example, not real environment variables
â””â”€â”€ README.md             # Documentation
```
---

## ğŸš€ Getting Started

Follow these steps to set up and run the ETL pipeline on your local machine.

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Dungpham0703/gold_etl_pipeline.git
cd gold_etl_pipeline
```

### 2ï¸âƒ£ Set Up Environment Variables
```bash
cp .env .env
```
Then open .env and fill in your real values:
```bash
GOLD_API_URL=https://www.goldapi.io/api/XAU/USD
GOLD_API_KEY=your_api_key_here
AIRFLOW_UID=50000
GMAIL_USER=youremail@gmail.com
GMAIL_PASSWORD=your_app_password
```
